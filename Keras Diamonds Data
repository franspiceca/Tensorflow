import pandas as pd
import numpy as np
from seaborn import load_dataset 
from sklearn.model_selection import train_test_split
import tensorflow as tf

from seaborn import load_dataset
df = load_dataset("diamonds")
df.head()

#Creating features and target
features = ['cut', 'color', 'clarity', 'carat', 'depth', 'table', 'x', 'y', 'z']
target = 'price'

#Changing to cagtegorical and dropping nulls (preparing for modeling)
df.cut = pd.Categorical(df.cut)
df.color = pd.Categorical(df.color)
df.clarity = pd.Categorical(df.clarity)

df.cut = df.cut.cat.codes
df.color = df.color.cat.codes
df.clarity = df.clarity.cat.codes

df = df.dropna()

df.head()

#Setting up feature and target variables
X = df[features]
y = df[target]

#Training/testing data set up
X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

#Validation data set up
X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=1)

#Setting up data to test against (new diamond inputs)
diamond1 = {"carat": 0.25, 
           "cut": 2,
           "color": 5,
           "clarity": 1,
           "depth": 62.6,
           "table": 58,
           "x": 3.93,
           "y": 4.07,
           "z": 2.73}

diamond2 = {"carat": 0.30, 
           "cut": 3,
           "color": 4,
           "clarity": 1,
           "depth": 63.7,
           "table": 59,
           "x": 3.97,
           "y": 4.00,
           "z": 2.78}

diamond3 = {"carat": 0.21, 
           "cut": 2,
           "color": 4,
           "clarity": 2,
           "depth": 61.6,
           "table": 56,
           "x": 3.73,
           "y": 3.97,
           "z": 2.78}

#Setting up new diamonds list with diamonds above
X_new = [] 
for diamond in [diamond1, diamond2, diamond3]:
    new_diamond = [diamond["carat"], diamond["cut"], diamond["color"], diamond["clarity"], diamond["depth"], 
                   diamond["table"], diamond["x"], diamond["y"], diamond["z"]]
    X_new.append(new_diamond)

#Making new diamonds a dataframe
X_new = pd.DataFrame(data=X_new, columns = X_train.columns)

#Train, test and validation data to slice
train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train))
valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid.values, y_valid))
test_dataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test))

x_new_dataset = tf.data.Dataset.from_tensor_slices((X_new.values, [0,0,0]))

#Displaying features and target data
for feat, targ in test_dataset.take(5):
  print ('Features: {}, Target: {}'.format(feat, targ))

#Setting batch size with data
batch_size = 1

train_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)
valid_dataset = valid_dataset.shuffle(len(X_valid)).batch(batch_size)
test_dataset = test_dataset.shuffle(len(X_test)).batch(batch_size)

x_new_dataset = x_new_dataset.batch(batch_size)

#Creating the different layers
model = tf.keras.Sequential([
    tf.keras.layers.Dense(units=9, activation='relu'),
    tf.keras.layers.Dense(units=10, activation='relu'),
    tf.keras.layers.Dense(units=10, activation='relu'),
    tf.keras.layers.Dense(units=10, activation='relu'),
    tf.keras.layers.Dense(units=1, activation ='sigmoid')
  ])

#Setting up the model (looking for accruary here)
model.compile(loss='binary_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

#Fitting thr model
model.fit(train_dataset,epochs=5, validation_data= valid_dataset)
